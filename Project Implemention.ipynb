{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.models import Model\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "import os\n",
    "import cv2\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = \"dataset\"\n",
    "\n",
    "# define the names of the training, testing, and validation\n",
    "# directories\n",
    "TRAIN = \"training\"\n",
    "\n",
    "# initialize the list of class label names\n",
    "CLASSES = [\"positive\", \"negative\"]\n",
    "# set the batch size\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# initialize the label encoder file path and the output directory to\n",
    "# where the extracted features (in CSV file format) will be stored\n",
    "LE_PATH = os.path.sep.join([\"output\", \"le.cpickle\"])\n",
    "BASE_CSV_PATH = \"output\"\n",
    "# set the path to the serialized model after training\n",
    "MODEL_PATH = os.path.sep.join([\"output\", \"model.cpickle\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading network...\n"
     ]
    }
   ],
   "source": [
    "# load the VGG16 network and initialize the label encoder\n",
    "print(\"[INFO] loading network...\")\n",
    "vgg16 = VGG16(weights=\"imagenet\", include_top=True)\n",
    "# Using fc2 layer as our feature vector\n",
    "featureExtractor = Model(inputs=vgg16.input, outputs=vgg16.get_layer('fc2').output)\n",
    "le = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing and Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] processing 'training split'...\n",
      "[INFO] processing batch 1/41\n",
      "[INFO] processing batch 2/41\n",
      "[INFO] processing batch 3/41\n",
      "[INFO] processing batch 4/41\n",
      "[INFO] processing batch 5/41\n",
      "[INFO] processing batch 6/41\n",
      "[INFO] processing batch 7/41\n",
      "[INFO] processing batch 8/41\n",
      "[INFO] processing batch 9/41\n",
      "[INFO] processing batch 10/41\n",
      "[INFO] processing batch 11/41\n",
      "[INFO] processing batch 12/41\n",
      "[INFO] processing batch 13/41\n",
      "[INFO] processing batch 14/41\n",
      "[INFO] processing batch 15/41\n",
      "[INFO] processing batch 16/41\n",
      "[INFO] processing batch 17/41\n",
      "[INFO] processing batch 18/41\n",
      "[INFO] processing batch 19/41\n",
      "[INFO] processing batch 20/41\n",
      "[INFO] processing batch 21/41\n",
      "[INFO] processing batch 22/41\n",
      "[INFO] processing batch 23/41\n",
      "[INFO] processing batch 24/41\n",
      "[INFO] processing batch 25/41\n",
      "[INFO] processing batch 26/41\n",
      "[INFO] processing batch 27/41\n",
      "[INFO] processing batch 28/41\n",
      "[INFO] processing batch 29/41\n",
      "[INFO] processing batch 30/41\n",
      "[INFO] processing batch 31/41\n",
      "[INFO] processing batch 32/41\n",
      "[INFO] processing batch 33/41\n",
      "[INFO] processing batch 34/41\n",
      "[INFO] processing batch 35/41\n",
      "[INFO] processing batch 36/41\n",
      "[INFO] processing batch 37/41\n",
      "[INFO] processing batch 38/41\n",
      "[INFO] processing batch 39/41\n",
      "[INFO] processing batch 40/41\n",
      "[INFO] processing batch 41/41\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# grab all image paths in the current split\n",
    "print(\"[INFO] processing '{} split'...\".format(TRAIN))\n",
    "p = os.path.sep.join([BASE_PATH, TRAIN])\n",
    "imagePaths = list(paths.list_images(p))\n",
    "# randomly shuffle the image paths and then extract the class\n",
    "# labels from the file paths\n",
    "random.shuffle(imagePaths)\n",
    "labels = [p.split(os.path.sep)[-2] for p in imagePaths]\n",
    "# if the label encoder is None, create it\n",
    "if le is None:\n",
    "    le = LabelEncoder()\n",
    "    le.fit(labels)\n",
    "# open the output CSV file for writing\n",
    "csvPath = os.path.sep.join([BASE_CSV_PATH, \"{}.csv\".format(TRAIN)])\n",
    "csv = open(csvPath, \"w\")\n",
    "# loop over the images in batches\n",
    "for (b, i) in enumerate(range(0, len(imagePaths), BATCH_SIZE)):\n",
    "    # extract the batch of images and labels, then initialize the\n",
    "    # list of actual images that will be passed through the network\n",
    "    # for feature extraction\n",
    "    print(\"[INFO] processing batch {}/{}\".format(b + 1, int(np.ceil(len(imagePaths) / float(BATCH_SIZE)))))\n",
    "    batchPaths = imagePaths[i:i + BATCH_SIZE]\n",
    "    batchLabels = le.transform(labels[i:i + BATCH_SIZE])\n",
    "    batchImages = []\n",
    "    # loop over the images and labels in the current batch\n",
    "    for imagePath in batchPaths:\n",
    "        # load the input image using the Keras helper utility\n",
    "        # while ensuring the image is resized to 224x224 pixels\n",
    "        image = load_img(imagePath, target_size=(224, 224))\n",
    "        image = img_to_array(image)\n",
    "        # preprocess the image by (1) expanding the dimensions and\n",
    "        # (2) subtracting the mean RGB pixel intensity from the\n",
    "        # ImageNet dataset\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "        image = preprocess_input(image)\n",
    "        # add the image to the batch\n",
    "        batchImages.append(image)\n",
    "    # pass the images through the network and use the outputs as\n",
    "    # our actual features, then reshape the features into a\n",
    "    # flattened volume\n",
    "    batchImages = np.vstack(batchImages)\n",
    "    features = featureExtractor.predict(batchImages, batch_size=BATCH_SIZE)\n",
    "    features = features.reshape((features.shape[0], 4096))\n",
    "    # loop over the class labels and extracted features\n",
    "    for (label, vec) in zip(batchLabels, features):\n",
    "        # construct a row that exists of the class label and\n",
    "        # extracted features\n",
    "        vec = \",\".join([str(v) for v in vec])\n",
    "        csv.write(\"{},{}\\n\".format(label, vec))\n",
    "# close the CSV file\n",
    "csv.close()\n",
    "\n",
    "# serialize the label encoder to disk\n",
    "f = open(LE_PATH, \"wb\")\n",
    "f.write(pickle.dumps(le))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_split(splitPath):\n",
    "    # initialize the data and labels\n",
    "    data = []\n",
    "    labels = []\n",
    "    # loop over the rows in the data split file\n",
    "    for row in open(splitPath):\n",
    "        # extract the class label and features from the row\n",
    "        row = row.strip().split(\",\")\n",
    "        label = row[0]\n",
    "        features = np.array(row[1:], dtype=\"float\")\n",
    "        # update the data and label lists\n",
    "        data.append(features)\n",
    "        labels.append(label)\n",
    "    # return a tuple of the data and labels\n",
    "    data = np.array(data)\n",
    "    labels = np.array(labels)\n",
    "    return (data, labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading data...\n"
     ]
    }
   ],
   "source": [
    "# derive the paths to the training and testing CSV files\n",
    "trainingPath = os.path.sep.join([BASE_CSV_PATH, \"{}.csv\".format(TRAIN)])\n",
    "# load the data from disk\n",
    "print(\"[INFO] loading data...\")\n",
    "(X, Y) = load_data_split(trainingPath)\n",
    "# load the label encoder from disk\n",
    "le = pickle.loads(open(LE_PATH, \"rb\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPlitting Training and Testing data\n",
    "trainX, testX, trainY, testY = train_test_split(X, Y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training model...\n",
      "[INFO] evaluating...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99       290\n",
      "    positive       0.99      0.97      0.98        99\n",
      "\n",
      "    accuracy                           0.99       389\n",
      "   macro avg       0.99      0.98      0.99       389\n",
      "weighted avg       0.99      0.99      0.99       389\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "print(\"[INFO] training model...\")\n",
    "model = SVC(kernel='linear')\n",
    "model.fit(trainX, trainY)\n",
    "# evaluate the model\n",
    "print(\"[INFO] evaluating...\")\n",
    "preds = model.predict(testX)\n",
    "print(classification_report(testY, preds, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(image, stepSize, windowSize):\n",
    "    # slide a window across the image\n",
    "    for y in range(0, image.shape[0], stepSize):\n",
    "        for x in range(0, image.shape[1], stepSize):\n",
    "            # yield the current window\n",
    "            yield (x, y, image[y:y + windowSize[1], x:x + windowSize[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = 'dataset/testing/IMG_700101_000223_0046_NIR.TIF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_image = cv2.imread(test_image)\n",
    "image = original_image.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "(winW, winH) = (100, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (x, y, window) in sliding_window(image, stepSize=100, windowSize=(winW, winH)):\n",
    "    # if the window does not meet our desired window size, ignore it\n",
    "    if window.shape[0] != winH or window.shape[1] != winW:\n",
    "        continue\n",
    "    # THIS IS WHERE YOU WOULD PROCESS YOUR WINDOW, SUCH AS APPLYING A\n",
    "    # MACHINE LEARNING CLASSIFIER TO CLASSIFY THE CONTENTS OF THE\n",
    "    # WINDOW\n",
    "    # since we do not have a classifier, we'll just draw the window\n",
    "    \n",
    "    \n",
    "    clone = window.copy()\n",
    "    \n",
    "    # Preprocess Image before Classification\n",
    "    resized = cv2.resize(clone, (224,224))\n",
    "    image2 = np.expand_dims(resized, axis=0)\n",
    "    image3 = preprocess_input(image2)\n",
    "    features = featureExtractor.predict(image3, batch_size=BATCH_SIZE)\n",
    "    pred = model.predict(features)[0]\n",
    "    \n",
    "    if(pred == '1'):\n",
    "        results.append([(x, y), (x + winW, y + winH)])\n",
    "        cv2.rectangle(image, (x, y), (x + winW, y + winH), (0, 255, 0), 2)\n",
    "#     cv2.imshow(\"Window\", clone)\n",
    "#     cv2.waitKey(1)\n",
    "#     time.sleep(0.025)\n",
    "#     break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image)\n",
    "plt.title('my picture')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
